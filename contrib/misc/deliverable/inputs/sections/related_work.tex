\section{Related Work}
\label{sec:related_work}

\noindent
{\bf Fault tolerance in distributed databases.} \ Distributed databases use replication and advanced request scheduling to improve data availability. Bayou~\cite{petersen1996bayou} is a data storage that relies on replication to ensure data availability against fail-stop failures, but they are not able to deal with performance anomalies. Skute~\cite{bonvin2010self} provides an adaptive replication scheme that mitigates the impact of performance anomalies. However, it does not provide mechanisms to ensure high data availability, such as high throughput and bounded latency. Emerging cloud databases, like VoltDB and MongoDB, offer high data availability using enhanced main memory data structures~\cite{stonebraker2010sql}. But, our findings of this and previous study~\cite{silvestre2014anomaly} show that performance anomalies on the cloud, including malfunctioning network cards, disk and main memory, can undermine the performance of cloud databases. 

Cake~\cite{wang2012cake} offers a scheduling scheme to enforce high-level data availability requirements for end users. However, Cake was not designed to identify faulty VMs. Eriksson \emph{et al.}~\cite{eriksson2013riskroute} provide a routing framework that helps cloud operators to mitigate the impact of network failures. We believe that our work is complementary to theirs. Alerts from Tejo about anomalies in network, memory, disk and CPU of VMs, can contribute to enhance the efficiency of such scheduling mechanisms.

\noindent
{\bf Anomaly detection with statistical learning.} \ Anomaly detection is commonly implemented based on an \emph{unsupervised learning method}. Gujrati \emph{et al.}~\cite{gujrati2007meta} provide prediction models based on event logs of supercomputers to detect platform-wide anomalies, whereas we are interested in detecting anomalous VMs based on monitoring data. Chen \emph{et al.}~\cite{chen2007failure} propose an anomaly detection approach for large-scale systems that improves the prediction efficiency of an entropy-based information theory technique by performing a principal component analysis (PCA) of system inputs. However, this introduces computational overhead that undermines its scalability and causes a slowdown in anomaly predictions. While we focus on detecting performance anomalies in NewSQL databases, Lan \emph{et al.}~\cite{lan2010toward} provide a general-purpose anomaly detection approach that relies on features selection to enhance prediction efficiency. Similarly, Guan and Fu~\cite{guan2013adaptive} perform feature extraction based on PCA to identify the most relevant inputs for anomaly detection. Yet, results of our previous work~\cite{silvestre2014anomaly} confirm that a supervised method with all features outperforms an unsupervised one by reducing the number of false positives by 10\%. In this work, we extended our previous supervised learning model to detect multiple classes of anomalies based on SLO metrics.

Guan \emph{et al.}~\cite{guan2012cda} implement a probabilistic prediction model based on a \emph{supervised learning method}. Although their model allows us to compare the dependability of virtualized and non-virtualized cloud systems, it suffers from poor prediction efficiency when it is used to predict cloud performance anomalies. Tan \emph{et al.}~\cite{tan2012prepare} propose general-purpose prediction model to prevent performance anomalies. Their \emph{supervised learning}-based model combines 2-dependent Markov chain model with the tree-augmented Bayesian networks. But, the authors did not provide information about the prediction efficiency and the capacity of their approach to generalize. We show with Tejo that the choice of the learning algorithm and features contribute to enhance predictive efficiency of performance anomalies.
